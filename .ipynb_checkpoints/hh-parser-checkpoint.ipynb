{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import requests\n",
    "import re\n",
    "\n",
    "import numpy\n",
    "import pandas as pd \n",
    "\n",
    "import json\n",
    "import csv\n",
    "from itertools import chain\n",
    "from typing import List\n",
    "from multiprocessing.dummy import Pool as ThreadPool "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vacancy_urls(initial_search_url: str) -> List[str]:\n",
    "    \n",
    "    def get_vacancy_urls_from_all_pages(search_url: str) -> List[str]:\n",
    "        total_pages_with_results = max([0] + [int(a.contents[0]) for a in BeautifulSoup(urllib.request.urlopen(search_url)).findAll(\"a\", {\"class\": \"HH-Pager-Control\"}) if len(a.contents[0]) <= 3])\n",
    "        vacancy_ulrs = []\n",
    "        for i in range(total_pages_with_results):\n",
    "            results_response = urllib.request.urlopen(search_url + f\"&page={i}\")\n",
    "            results_soup = BeautifulSoup(results_response)\n",
    "            vacancy_divs = results_soup.findAll(\"div\", {\"class\": \"vacancy-serp-item\"})\n",
    "            vacancy_ulrs += [div.findAll(\"a\", {\"class\":\"HH-LinkModifier\"})[0]['href'] for div in vacancy_divs]\n",
    "        return vacancy_ulrs\n",
    "\n",
    "    initial_search_results_page = urllib.request.urlopen(initial_search_url)\n",
    "    initial_search_results_soup = BeautifulSoup(initial_search_results_page)\n",
    "    clusters = initial_search_results_soup.findAll(\"div\", {\"class\": \"clusters-group-title\"})\n",
    "    divs = [c for c in clusters if c.attrs[\"data-toggle\"] in [\"professionalArea\", \"industry\"]]\n",
    "    cildren_contents = [[c for c in div.findNextSibling().children][0].contents for div in divs]\n",
    "    urls_with_filters = [initial_search_url.split('?')[0] + url_ending for url_ending in list(chain(*[[el.findAll(\"a\")[0].attrs[\"href\"] for el in [c1 for c1 in c[1:]] if len(el.findAll(\"a\"))] for c in cildren_contents]))]\n",
    "    return list(set(chain(*[get_vacancy_urls_from_all_pages(url) for url in urls_with_filters])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_in_smr_url = \"https://samara.hh.ru/search/vacancy?text=&area=78&salary=&currency_code=RUR&experience=doesNotMatter&employment=full&employment=part&employment=project&schedule=fullDay&schedule=shift&schedule=flexible&schedule=flyInFlyOut&order_by=relevance&search_period=&items_on_page=100&no_magic=true\"\n",
    "search_in_spb_url = \"https://spb.hh.ru/search/vacancy?text=&area=2&salary=&currency_code=RUR&only_with_salary=true&experience=doesNotMatter&employment=full&employment=part&employment=project&schedule=fullDay&schedule=shift&schedule=flexible&schedule=flyInFlyOut&order_by=salary_desc&search_period=&items_on_page=100&no_magic=true\"\n",
    "search_in_kzn_url = \"https://kazan.hh.ru/search/vacancy?text=&area=88&salary=&currency_code=RUR&experience=doesNotMatter&employment=full&employment=part&employment=project&schedule=fullDay&schedule=shift&schedule=flexible&schedule=flyInFlyOut&order_by=relevance&search_period=&items_on_page=100&no_magic=true\"\n",
    "search_in_vdk_url = \"https://vladivostok.hh.ru/search/vacancy?text=&area=22&salary=&currency_code=RUR&experience=doesNotMatter&employment=full&employment=part&employment=project&schedule=fullDay&schedule=shift&schedule=flexible&schedule=flyInFlyOut&order_by=relevance&search_period=&items_on_page=100&no_magic=true\"\n",
    "\n",
    "smr_urls = get_vacancy_urls(search_in_smr_url)\n",
    "vdk_urls = get_vacancy_urls(search_in_vdk_url)\n",
    "kzn_urls = get_vacancy_urls(search_in_kzn_url)\n",
    "spb_urls = get_vacancy_urls(search_in_spb_url)\n",
    "\n",
    "with open(\"./hh-data/smr-urls.txt\", \"w\") as file:\n",
    "    file.write(\"\\n\".join(smr_urls))\n",
    "with open(\"./hh-data/vdk-urls.txt\", \"w\") as file:\n",
    "    file.write(\"\\n\".join(vdk_urls))\n",
    "with open(\"./hh-data/spb-urls.txt\", \"w\") as file:\n",
    "    file.write(\"\\n\".join(spb_urls))\n",
    "with open(\"./hh-data/kzn-urls.txt\", \"w\") as file:\n",
    "    file.write(\"\\n\".join(kzn_urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_paerser_results_row(url: str) -> List[str]:\n",
    "    results_response = urllib.request.urlopen(url)\n",
    "    results_soup = BeautifulSoup(results_response)\n",
    "\n",
    "    adress_spans = results_soup.findAll('span', {'data-qa': 'vacancy-view-raw-address'})\n",
    "    salary_classes = results_soup.findAll('p', {'class': 'vacancy-salary'})\n",
    "    \n",
    "    return [url, adress_spans[0].contents[1] if adress_spans else '', salary_classes[0].contents[0] if salary_classes else '']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./hh-data/urls/spb-urls.txt\") as file:\n",
    "    spb_urls = file.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27810"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(spb_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(l, n):\n",
    "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(url):    \n",
    "    try:\n",
    "        row = basic_paerser_results_row(url)\n",
    "        if not row[1]:\n",
    "            no_adress_table.append(row)\n",
    "        elif not row[2]:\n",
    "            no_salary_table.append(row)\n",
    "        else:\n",
    "            completed_table.append(row)\n",
    "    except urllib.error.HTTPError:\n",
    "        print(url)\n",
    "    except IndexError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "spb_urls_chunks = chunks(spb_urls, 10)\n",
    "for chunk in spb_urls_chunks:\n",
    "    completed_table = []\n",
    "    no_adress_table = []\n",
    "    no_salary_table = []\n",
    "    \n",
    "    # make the Pool of workers\n",
    "    pool = ThreadPool(8) \n",
    "\n",
    "    # open the urls in their own threads\n",
    "    # and return the results\n",
    "    results = pool.map(f, chunk)\n",
    "\n",
    "    # close the pool and wait for the work to finish \n",
    "    pool.close() \n",
    "    pool.join()\n",
    "    \n",
    "    with open(\"./hh-data/tables/spb/completed.csv\", \"a\") as file:\n",
    "        file.write('\\n'.join(['; '.join(row) for row in completed_table]) + '\\n' )\n",
    "        \n",
    "    with open(\"./hh-data/tables/spb/no-adress.csv\", \"a\") as file:\n",
    "        file.write('\\n'.join(['; '.join(row) for row in no_adress_table]) + '\\n' * bool(len(no_adress_table)))\n",
    "        \n",
    "    with open(\"./hh-data/tables/spb/no-salary.csv\", \"a\") as file:\n",
    "        file.write('\\n'.join(['; '.join(row) for row in no_salary_table]) + '\\n' * bool(len(no_salary_table)))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://spb.hh.ru/vacancy/30562789, Новочеркасская, Санкт-Петербург, Заневский проспект, 30к2, от 35 000 руб. на руки\n",
      "https://spb.hh.ru/vacancy/29725192, Парк Победы, Санкт-Петербург, Витебский проспект, 17к6, от 27 000 руб. на руки\n",
      "https://spb.hh.ru/vacancy/30713174, Звёздная, Санкт-Петербург, 2 линия, метро Звёздная, от 74 713 до 74 713 руб. до вычета НДФЛ\n",
      "https://spb.hh.ru/vacancy/30657031, Технологический институт, Санкт-Петербург, Измайловский пр., 15, от 50 000 руб. на руки\n",
      "https://spb.hh.ru/vacancy/30590865, Ломоносовская, Санкт-Петербург, улица Кибальчича, 26, от 60 000 руб. на руки\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join([', '.join(row) for row in completed_table]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://spb.hh.ru/vacancy/30355862',\n",
       " 'Санкт-Петербург, переулок Челиева, 13',\n",
       " 'от 35\\xa0000 до 120\\xa0000 грн. до вычета НДФЛ']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
