{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url to first pages\n",
    "# enter cian.ru and avito.ru urls of desired city and a name of the city\n",
    "cian_url = \"https://spb.cian.ru/cat.php?deal_type=sale&engine_version=2&offer_type=flat&region=2&room1=1&room2=1&room3=1&room4=1&room5=1&room6=1&room7=1&room9=1\"\n",
    "# avito_url = \"https://www.avito.ru/sankt-peterburg/kvartiry?s_trg=1\"\n",
    "avito_url = 'https://www.avito.ru/sankt-peterburg/kvartiry/prodam?f=549_5695-5696-5697-5698-5699-5700-5701-11018-11019-11020-11021&s_trg=4'\n",
    "city = \"Санкт-Петербург\"\n",
    "\n",
    "#example of samara urls\n",
    "# avito_url = 'https://www.avito.ru/samara/kvartiry?s_trg=3'\n",
    "# cian_url = 'https://samara.cian.ru/cat.php?deal_type=sale&engine_version=2&offer_type=flat&region=4966&room1=1&room2=1&room3=1&room4=1&room5=1&room6=1&room9=1'\n",
    "# city = 'Самара'\n",
    "\n",
    "csv_dir = 'csv-data'\n",
    "api_key = '800e1c1a-3d68-496e-88a9-009b98d7eb75'\n",
    "api_url = 'https://geocode-maps.yandex.ru/1.x/?apikey=' + api_key + '&format=json&geocode=' + city + ',+'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute this cell to load all neccessary functions\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import requests\n",
    "import re\n",
    "\n",
    "#write collected data to .csv file as a pandas dataframe\n",
    "import numpy\n",
    "import pandas as pd \n",
    "\n",
    "#decode geotagging answer\n",
    "import json\n",
    "import csv\n",
    "\n",
    "#avito\n",
    "#extract price\n",
    "def price_from_json(flat):\n",
    "    price = flat.find(\"div\", {\"class\": \"popup-prices\"})\n",
    "    if price != None:\n",
    "        price = price['data-prices']\n",
    "    else:\n",
    "        return -1\n",
    "    price_ind = price.find('RUB\":')\n",
    "    price_cut = price[price_ind + 5:]\n",
    "    price_in_rub = price_cut.split(\",\")[0]\n",
    "    return int(price_in_rub)\n",
    "\n",
    "#extract all relevant data from single page\n",
    "def parse_page_avito(flats, data_flats):\n",
    "    rent_count = 0\n",
    "    print(\"flats on page: \", len(flats))\n",
    "    for (index, flat) in enumerate(flats):\n",
    "\n",
    "        print(\"Flat number\", index)\n",
    "\n",
    "        #price\n",
    "        print(\"price:\")\n",
    "        price = price_from_json(flat)\n",
    "        if(price < 300_000):\n",
    "            rent_count += 1\n",
    "            print(\"Rent found, skip. price = \", price)\n",
    "            continue\n",
    "        print(price)\n",
    "        print()\n",
    "\n",
    "\n",
    "        #rooms, area, floor level\n",
    "        print(\"rooms:\")\n",
    "        description = flat.find(\"a\", {\"class\": \"item-description-title-link\"})['title']\n",
    "        try_rooms = description.split(\",\")[0][0]\n",
    "        if try_rooms.isnumeric():\n",
    "            rooms = int(try_rooms)\n",
    "        else:\n",
    "            rooms = 1\n",
    "        print(rooms)\n",
    "        print()\n",
    "\n",
    "        print(\"area:\")\n",
    "        area = float(description.split(\",\")[1].split(\" \")[1])\n",
    "        print(area, \"m^2\")\n",
    "        print()\n",
    "\n",
    "        print(description)\n",
    "\n",
    "        print(\"floor:\")\n",
    "        floor = description.split(\",\")[2].split(\" \")[1].split(\"/\")[0]\n",
    "        print('floors total = ', description)\n",
    "        floors_total = description.split(\",\")[2].split(\" \")[1].split(\"/\")[1]\n",
    "        print(\"\" + floor + \", total floors: \" + floors_total)\n",
    "        print()\n",
    "\n",
    "        #subway, distance to subway, adress\n",
    "        full_adress = flat.find(\"p\", {\"class\": \"address\"}).getText()\n",
    "\n",
    "        adress = ','.join(full_adress.split(\",\")[1:])\n",
    "        print(\"adress:\")\n",
    "        print(adress)\n",
    "        print()\n",
    "\n",
    "        subway = full_adress.split(\",\")[0]\n",
    "        for (ind,el) in enumerate(subway.split()):\n",
    "            try:\n",
    "                float(el)\n",
    "                subway_station = ' '.join(subway.split()[:ind])\n",
    "                distance = float(subway.split()[ind])\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "        print(\"subway:\")\n",
    "        print(subway_station)\n",
    "        print()\n",
    "\n",
    "        if distance < 99:\n",
    "            distance *= 1000\n",
    "        print(\"distance to subway:\")\n",
    "        print(distance, \"meters\")\n",
    "        print()\n",
    "\n",
    "        print(\"go to next page\")\n",
    "        data_flats.append((price, rooms, area, floor, floors_total, adress, subway_station, distance))\n",
    "    \n",
    "    print(rent_count)\n",
    "    return data_flats\n",
    "\n",
    "\n",
    "def parse_avito(avito_url):\n",
    "    avito_real_estate = urllib.request.urlopen(avito_url).read()\n",
    "    #parse avito with beautiful soup\n",
    "    avito_soup = BeautifulSoup(avito_real_estate)\n",
    "    # url_base = \"https://www.avito.ru\"\n",
    "    flats = avito_soup.findAll(\"div\", {\"class\":\"item_table-description\"})\n",
    "    page_count = 0\n",
    "\n",
    "    data_flats = parse_page_avito(flats, [])\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            page_count += 1\n",
    "            print(\"Page: \", page_count)\n",
    "            next_page = avito_soup.find(\"a\", {\"class\":\"pagination-page\"}).get('href')\n",
    "            flats = avito_soup.findAll(\"div\", {\"class\":\"item_table-description\"})\n",
    "            data_flats = parse_page_avito(flats, data_flats)\n",
    "\n",
    "            if page_count > 100:\n",
    "                print('page count > 100, break')\n",
    "                break\n",
    "        except Exception as error:\n",
    "            print(error, ' error, break')\n",
    "            break\n",
    "\n",
    "    print(\"finish, page count = \", page_count)\n",
    "    print(\"data len: \", len(data_flats))\n",
    "    new_data_flats = []\n",
    "    for flat in data_flats:\n",
    "        new_flat = (flat[0],flat[1],flat[2],flat[3],flat[4],flat[5].replace('\\xa0', '', 2),flat[6],flat[7])\n",
    "        new_data_flats.append(new_flat)\n",
    "    \n",
    "    return new_data_flats\n",
    "\n",
    "def write_to_csv(new_data_flats, file_name):\n",
    "    \n",
    "    a = numpy.asarray(new_data_flats)\n",
    "    pd.DataFrame(a).to_csv(csv_dir + '/' + file_name, header=['price', 'rooms', 'area', 'floor', 'floors_total', 'adress',\n",
    "                                           'subway_station', 'distance to subway'])\n",
    "\n",
    "#cian\n",
    "    \n",
    "def next_page_cian(first_page, soup):\n",
    "    next_p = soup.find(\"li\", {\"class\": re.compile('^.*list-item--active.*')})\n",
    "    if next_p and next_p.nextSibling:\n",
    "        return next_p.nextSibling.a['href']\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def parse_cian_page(cian_soup, data_flats):\n",
    "    counter = 0\n",
    "    flats = cian_soup.findAll(\"div\", {\"class\": \"c6e8ba5398--info-container--YhZ2y\"})\n",
    "    print('flats = ',len(flats))\n",
    "    for flat in flats:\n",
    "        \n",
    "        counter += 1\n",
    "        # rooms, area, floor\n",
    "        addr = flat.find(\"div\", {\"class\": re.compile('^.*title.*')})\n",
    "        if addr:\n",
    "            try:\n",
    "                rooms = int(addr.text[0])\n",
    "                print('rooms = ', rooms)\n",
    "            except Exception:\n",
    "                rooms = 1\n",
    "            try:\n",
    "                area = float(addr.text.split(',')[1].split()[0])\n",
    "            except Exception as error:\n",
    "                print(error,', area error, area = ', addr.text.split(',')[1].split()[0])\n",
    "                continue\n",
    "            print('full addr = ', addr.text)\n",
    "            print('area = ', area)\n",
    "            floor = int(addr.text.split(',')[2].split(' ')[1].split('/')[0])\n",
    "            print('floors = ', floor)\n",
    "            try:\n",
    "                floors_total = int(addr.text.split(',')[2].split(' ')[1].split('/')[1])\n",
    "            except Exception as error:\n",
    "                print('floors total error = ', error)\n",
    "            print('floors total = ', floors_total)\n",
    "            \n",
    "            print(addr.text)\n",
    "\n",
    "        subway = flat.find(\"div\", {\"class\": re.compile('^.*underground-name.*')})\n",
    "        if subway:\n",
    "            subway = subway.text\n",
    "            print(subway)\n",
    "        else:\n",
    "            subway = None\n",
    "\n",
    "        remoteness = flat.find(\"div\", {\"class\": re.compile('^.*remoteness.*')})\n",
    "        if remoteness:\n",
    "            print(remoteness.text)\n",
    "            if remoteness.text.split('\\xa0')[2] == 'пешком':\n",
    "                remoteness = int(remoteness.text.split('\\xa0')[0]) * 100\n",
    "            else:\n",
    "                remoteness = int(remoteness.text.split('\\xa0')[0]) * 1000\n",
    "            print('distance to subway = ',remoteness)\n",
    "        else:\n",
    "            remoteness = None\n",
    "            \n",
    "        adress = flat.findAll(\"a\", {\"class\": re.compile('^.*address.*')})\n",
    "        if adress:\n",
    "            if(len(adress) > 5):\n",
    "                adress = adress[4].text+ ', ' + adress[5].text\n",
    "                print(adress)\n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "        price = flat.find(\"div\", {\"class\": re.compile('^.*price.*')}).find(\"div\",{'class': re.compile('.*header.*')})\n",
    "        if price:\n",
    "            print(price.text)\n",
    "            price_array = price.text.split(' ')[:len(price.text.split(' ')) - 1]\n",
    "            price = 0\n",
    "            for el in price_array:\n",
    "                price *= 1000\n",
    "                price += int(el)\n",
    "            print('price = ', price)\n",
    "            \n",
    "        data_flats.append((price, rooms, area, floor, floors_total, adress, subway, remoteness))\n",
    "        print()\n",
    "    return data_flats\n",
    "\n",
    "def parse_cian(cian_url):\n",
    "    base_url = cian_url.split('cian.ru')[0] + 'cian.ru' \n",
    "    cian_real_estate = urllib.request.urlopen(cian_url).read()\n",
    "    cian_soup = BeautifulSoup(cian_real_estate)\n",
    "    counter = 0\n",
    "    flats = []\n",
    "    pages = 58\n",
    "    while counter < pages:\n",
    "        counter += 1\n",
    "        flats = parse_cian_page(cian_soup, flats)\n",
    "        cian_url = next_page_cian(cian_url, cian_soup)\n",
    "        if cian_url == -1:\n",
    "            break\n",
    "        if base_url not in cian_url:\n",
    "            cian_url = base_url + cian_url\n",
    "        print(\"url = \", cian_url)\n",
    "        cian_html = urllib.request.urlopen(cian_url).read()\n",
    "        cian_soup = BeautifulSoup(cian_html)\n",
    "        print(\"counter = \", counter)\n",
    "    return flats\n",
    "        \n",
    "        \n",
    "#add geotagging to existing csv file\n",
    "def geotag(file_in, file_out):\n",
    "    with open(file_in) as csv_file, open(file_out, 'w') as out:\n",
    "\n",
    "        writer = csv.writer(out, delimiter=',', quoting=csv.QUOTE_MINIMAL)\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        for ind, row in enumerate(csv_reader):\n",
    "            print('row ', ind)\n",
    "            if ind == 0:\n",
    "                writer.writerow((*row, 'longitude', 'latitude'))\n",
    "\n",
    "            else:\n",
    "                #TODO replace spaces with '+'\n",
    "                print('requested address = ', row[6].replace(' ','+'))\n",
    "                print('full url = ',api_url + row[6].replace(' ','+') )\n",
    "                r = requests.get(api_url + row[6].replace(' ','+'))\n",
    "                d = json.loads(r.text)\n",
    "                if d['response']['GeoObjectCollection']['metaDataProperty']['GeocoderResponseMetaData']['found'] != 0:\n",
    "                    longitude, latitude = d['response']['GeoObjectCollection']['featureMember'][0]['GeoObject']['Point']['pos'].split()\n",
    "                    print('long = ', longitude, ', latitude = ', latitude)\n",
    "                    writer.writerow((*row, longitude, latitude))\n",
    "                    out.flush()\n",
    "                else:\n",
    "                    print(\"geoposition not found, row skipped\")\n",
    "                \n",
    "#merge two data files\n",
    "def merge(first, second, out):\n",
    "    \n",
    "    with open(first) as cian, open(second) as avito, open(out, 'w') as out:\n",
    "        writer = csv.writer(out, delimiter=',', quoting=csv.QUOTE_MINIMAL)\n",
    "        cian_reader = csv.reader(cian, delimiter=',')\n",
    "        avito_reader = csv.reader(avito, delimiter =',')\n",
    "\n",
    "        for row in avito_reader:\n",
    "            writer.writerow(row)\n",
    "\n",
    "        for row in cian_reader:\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# необходимо сначала исполнить следующую ячейку, чтобы загрузить все функции\n",
    "# работает долго\n",
    "\n",
    "# avito to csv\n",
    "print('start avito parsing, url = ', avito_url)\n",
    "avito_flats = parse_avito(avito_url)\n",
    "write_to_csv(avito_flats, 'spb_test_avito.csv')\n",
    "print('finished avito parsing')\n",
    "\n",
    "# cian to csv\n",
    "print('start cian parsing, url = ', cian_url)\n",
    "cian_flats = parse_cian(cian_url)\n",
    "write_to_csv(cian_flats, 'spb_test_cian.csv')\n",
    "print('finished cian parsing')\n",
    "\n",
    "# merge\n",
    "print('merging cian and avito data')\n",
    "merge('spb_test_avito.csv', 'spb_test_cian.csv', 'spb_test_merged.csv')\n",
    "\n",
    "# geotag\n",
    "print('geotag all data')\n",
    "geotag('spb_test_merged.csv', 'spb_test_geotagged.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
